{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransposerNN(nn.Module):\n",
    "\n",
    "    def __init__(self, config_layer):\n",
    "        \"\"\" Arguments:\n",
    "                config_layer_list: a tensor used to configure network.\n",
    "                    all input should have the same shape as the config_layer.\n",
    "        \"\"\"\n",
    "        super(TransposerNN, self).__init__()\n",
    "        self.d1, self.d2 = config_layer.size()\n",
    "        # define 8-9 linear layers\n",
    "\n",
    "        self.ll_1 = nn.Sequential(nn.Linear(self.d1 * self.d2, self.d2), nn.ReLU())\n",
    "        self.ll_2 = nn.Sequential(nn.Linear(self.d2, self.d1), nn.ReLU())\n",
    "        self.ll_3 = nn.Sequential(nn.Linear(self.d1, self.d1), nn.ReLU())\n",
    "        self.ll_4 = nn.Sequential(nn.Linear(self.d1, self.d1), nn.ReLU())\n",
    "        self.ll_5 = nn.Sequential(nn.Linear(self.d1, self.d1), nn.ReLU())\n",
    "        self.ll_6 = nn.Sequential(nn.Linear(self.d1, self.d1 * self.d2), nn.ReLU())\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_layer):\n",
    "        \"\"\" Arguments:\n",
    "                input_layer: a tensor to be passed through the network. Should have the shape of (self.d1, self.d2)\n",
    "            Returns:\n",
    "                A tensor of shape (self.d1, self.d2).\n",
    "        \"\"\"\n",
    "        #print(input_layer.shape)\n",
    "        l1_out = self.ll_1(input_layer)\n",
    "        l2_out = self.ll_2(l1_out)\n",
    "        l3_out = self.ll_3(l2_out)\n",
    "        l4_out = self.ll_4(l3_out)\n",
    "        l5_out = self.ll_5(l4_out)\n",
    "        l6_out = self.ll_6(l5_out)\n",
    "\n",
    "        return l6_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../test.pkl')\n",
    "\n",
    "input_data = []\n",
    "target_data = []\n",
    "for i in range(len(data)):\n",
    "    if i % 2 == 0:\n",
    "        input_data.append(data[i][0])\n",
    "    else:\n",
    "        target_data.append(data[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "(150, 128, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(len(input_data[0]))\n",
    "print(np.array(input_data[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNet = TransposerNN(input_data[0][0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2048])\n",
      "torch.Size([128, 2048])\n",
      "tensor([[0.0000, 0.0964, 0.0000,  ..., 0.0000, 0.0616, 0.0467],\n",
      "        [0.0000, 0.0551, 0.1295,  ..., 0.0000, 0.0611, 0.0000],\n",
      "        [0.0000, 0.1134, 0.0000,  ..., 0.0159, 0.0523, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0118,  ..., 0.0546, 0.0000, 0.0759],\n",
      "        [0.0000, 0.0000, 0.0678,  ..., 0.1164, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0889, 0.0132, 0.0000]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(input_data[0][0].shape)\n",
    "out = myNet(torch.flatten(input_data[0][0]).cuda())\n",
    "out = out.view(input_data[0][0].shape)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is in the form of:\n",
    "# datum = [\n",
    "    #     big_array,  # ORIG ACTIV\n",
    "    #     orig_classification,  # ORIG LABEL | [1,0] TRUE [0,1] FALSE\n",
    "    #     None,  # this no longer used\n",
    "    #     model_name,  # LANG MODEL: model_name an abstraction for 'gpt2'\n",
    "    #     {'num_gpt2_iters': num_gpt2_iters_run, \\\n",
    "    #         'orig_tokens': orig_tokens, \\\n",
    "    #         'gpt2_generated_tokens': gpt2_generated_tokens},  # META DATA\n",
    "    #     orig_text,  # ORIG TEXT (or what we're deeming 'originial text')\n",
    "    #     None,  # PRED TEXT this literally won't exist until we have an NPI\n",
    "    #     TARG[0],  # TARG TEXT\n",
    "    #     gpt2_generated_text  # GPT2 TEXT: just generated right here by the GPT2 :D :D\n",
    "    # ]\n",
    "print(data[0][0][0].size())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edd5bf0df4cdbbc4b590a002e4e35358f485d57015d3861c2b30129929275b90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
