{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/libs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our file imports\n",
    "from music_transformer import *\n",
    "from transformer_training_helpers import *\n",
    "from song_classification import *\n",
    "from dataset import *\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "# musicautobot\n",
    "from musicautobot.numpy_encode import *\n",
    "from musicautobot.config import *\n",
    "from musicautobot.music_transformer import *\n",
    "from musicautobot.utils.midifile import *\n",
    "from musicautobot.utils.file_processing import process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_decode(model, src, src_mask, max_len, start_symbol, k):\n",
    "  memory = model.encode(src, src_mask)\n",
    "  ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "  for i in range(max_len-1):\n",
    "    out, w2 = model.decode(memory, src_mask,\n",
    "                       Variable(ys),\n",
    "                       Variable(subsequent_mask(ys.size(1))\n",
    "                                .type_as(src.data)))\n",
    "    prob = model.generator(out[:, -1])\n",
    "    _, next_words = torch.topk(prob, k = k, dim = 1)\n",
    "    # if starting, then create \n",
    "    #print(next_words)\n",
    "    if i == 0:\n",
    "      next_word = next_words[0][0].data.item()\n",
    "    else:\n",
    "      k2 = random.randint(0,k-1)\n",
    "      next_word = next_words[0][k2].data.item()\n",
    "    #print(next_word)\n",
    "    #k = random.randint(0,4)\n",
    "    #next_word = next_words[k].data[0]\n",
    "    ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "  \n",
    "  return ys\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out, w2 = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1) # change this for top k\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from previous state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'v'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/trevor/Desktop/MusGen/src/libs/output_transformer.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/trevor/Desktop/MusGen/src/libs/output_transformer.ipynb#ch0000004?line=0'>1</a>\u001b[0m myModel \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m../models/epochs_30_LM.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:593\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=590'>591</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=591'>592</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=592'>593</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:763\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=756'>757</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(f, \u001b[39m'\u001b[39m\u001b[39mreadinto\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m2\u001b[39m):\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=757'>758</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=758'>759</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=759'>760</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived object of type \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=760'>761</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfunctionality.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(f)))\n\u001b[0;32m--> <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=762'>763</a>\u001b[0m magic_number \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39;49mload(f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=763'>764</a>\u001b[0m \u001b[39mif\u001b[39;00m magic_number \u001b[39m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m    <a href='file:///home/trevor/.local/lib/python3.8/site-packages/torch/serialization.py?line=764'>765</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid magic number; corrupt file?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'."
     ]
    }
   ],
   "source": [
    "myModel = torch.load('../models/epochs_30_LM.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDs = MidiDataset('../numpy_path', 150, 'N/A', '.npy')\n",
    "dataloader = DataLoader(myDs, 1, shuffle=True)\n",
    "\n",
    "for _, item in enumerate(dataloader):\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = './saved_data/'\n",
    "# data_save_name = 'music_item_data_0-10000.pkl'\n",
    "# numpy_path = '../numpy_path'\n",
    "\n",
    "# numpy_files = get_files(numpy_path, extensions='.npy', recurse=True); len(numpy_files)\n",
    "\n",
    "# def create_databunch(files, path):\n",
    "#     #save_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "#     vocab = MusicVocab.create()\n",
    "#     processors = [OpenNPFileProcessor(), MusicItemProcessor()]\n",
    "\n",
    "#     #data = MusicDataBunch.from_files(midi_files, path, processors=processors, encode_position=True)\n",
    "#     data = MusicDataBunch.from_files(files, path, processors=processors, encode_position=True)\n",
    "#     return data\n",
    "\n",
    "# all_data = create_databunch(numpy_files, data_path); all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myDs[0])\n",
    "new_tens = myDs[0].reshape(myDs[0].shape[0] * myDs[0].shape[1])\n",
    "print(new_tens.shape)\n",
    "print(new_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate topk/greedy outputs from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.eval()\n",
    "# ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "#src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]))\n",
    "#src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]])).cuda()\n",
    "idx = 1\n",
    "src = myDs[idx].reshape(myDs[idx].shape[0] * myDs[idx].shape[1])[:100].unsqueeze(dim=0).long().cuda() # all_data.valid_ds[1][0].to_tensor()[:100].unsqueeze(dim=0)\n",
    "#print(src.size())\n",
    "src_mask = Variable(torch.ones(1, 1, 100)).unsqueeze(dim=0).cuda() # 26 was 10\n",
    "output = greedy_decode(myModel.cuda(), src, src_mask, max_len=100, start_symbol=0)\n",
    "output2 = topk_decode(myModel.cuda(), src, src_mask, max_len=100, start_symbol=0, k=2)\n",
    "\n",
    "#print(output2[0])\n",
    "#print(output[0])\n",
    "\n",
    "output.cuda()\n",
    "output2.cuda()\n",
    "\n",
    "print(\"GREEDY: \", output[0])\n",
    "print(\"TOPK: \", output2[0])\n",
    "print(\"SRC: \", src[0])\n",
    "\n",
    "ncorrect = 0\n",
    "for i in range(len(src)):\n",
    "  if src[0][i] == output2[0][i]:\n",
    "    ncorrect += 1\n",
    "print(\"TOPK: \", ncorrect / len(src[0]))\n",
    "\n",
    "ncorrect = 0\n",
    "for i in range(len(src)):\n",
    "  if src[0][i] == output[0][i]:\n",
    "    ncorrect += 1\n",
    "print(\"GREEDY: \", ncorrect / len(src[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert outputs to .mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from music21 import *\n",
    "import fluidsynth\n",
    "#environment.set()\n",
    "#print(output)\n",
    "output[0, 1] = 1\n",
    "output2[0, 1] = 1\n",
    "#print(src.cpu().numpy())\n",
    "temp_vocab = MusicVocab.create()\n",
    "#print(temp_vocab.stoi)\n",
    "MI = temp_vocab.to_music_item(src.cpu().numpy()[0])\n",
    "MO = temp_vocab.to_music_item(output.cpu().numpy()[0])\n",
    "MT = temp_vocab.to_music_item(output2.cpu().numpy()[0])\n",
    "print(\"SRC.SHP: \", src.shape)\n",
    "print(\"OUTPUT.SHP: \", output.shape)\n",
    "print(\"OUTPUT2.SHP: \", output2.shape)\n",
    "print(src)\n",
    "print(output)\n",
    "print(output2)\n",
    "#print(MI.to_text())\n",
    "#print(MO.to_text())\n",
    "#print(MT.to_text())\n",
    "\n",
    "#new_tens = myDs[0].reshape(myDs[0].shape[0] * myDs[0].shape[1])\n",
    "\n",
    "MMM = temp_vocab.to_music_item(new_tens.numpy().astype(int))\n",
    "MI.stream.write('midi', fp='./temp/inp.mid')\n",
    "MO.stream.write('midi', fp='./temp/pred.mid')\n",
    "MT.stream.write('midi', fp='./temp/topk.mid')\n",
    "#MMM.stream.write('midi', fp='./temp_outputs/inp_test.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify generated song's musical key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mitem = MusicItem.from_file('./temp/inp.mid', MusicVocab.create())\n",
    "m_item = MusicItem.from_file('./temp/topk.mid', MusicVocab.create())\n",
    "m_item2 = MusicItem.from_file('./temp/pred.mid', MusicVocab.create())\n",
    "print(src_mitem.to_text())\n",
    "print(int_to_note(34))\n",
    "print(calculate_score(src_mitem))\n",
    "print(calculate_score(m_item))\n",
    "print(calculate_score(m_item2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert .mid to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './temp_outputs/inp.mid'\n",
    "fs = FluidSynth(sound_font='../misc/FluidR3_GM.sf2')\n",
    "fs.midi_to_audio(filepath, '{}.wav'.format(filepath))\n",
    "\n",
    "filepath = './temp_outputs/pred.mid'\n",
    "fs = FluidSynth(sound_font='../misc/FluidR3_GM.sf2')\n",
    "fs.midi_to_audio(filepath, '{}.wav'.format(filepath))\n",
    "\n",
    "filepath = './temp_outputs/topk.mid'\n",
    "fs = FluidSynth(sound_font='../misc/FluidR3_GM.sf2')\n",
    "fs.midi_to_audio(filepath, '{}.wav'.format(filepath))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
