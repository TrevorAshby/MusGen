{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/libs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our file imports\n",
    "from music_transformer import *\n",
    "from transformer_training_helpers import *\n",
    "from song_classification import *\n",
    "from dataset import *\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "# musicautobot\n",
    "from musicautobot.numpy_encode import *\n",
    "from musicautobot.config import *\n",
    "from musicautobot.music_transformer import *\n",
    "from musicautobot.utils.midifile import *\n",
    "from musicautobot.utils.file_processing import process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_decode(model, src, src_mask, max_len, start_symbol, k):\n",
    "  memory = model.encode(src, src_mask)\n",
    "  ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "  for i in range(max_len-1):\n",
    "    out, w2 = model.decode(memory, src_mask,\n",
    "                       Variable(ys),\n",
    "                       Variable(subsequent_mask(ys.size(1))\n",
    "                                .type_as(src.data)))\n",
    "    prob = model.generator(out[:, -1])\n",
    "    _, next_words = torch.topk(prob, k = k, dim = 1)\n",
    "    # if starting, then create \n",
    "    #print(next_words)\n",
    "    if i == 0:\n",
    "      next_word = next_words[0][0].data.item()\n",
    "    else:\n",
    "      k2 = random.randint(0,k-1)\n",
    "      next_word = next_words[0][k2].data.item()\n",
    "    #print(next_word)\n",
    "    #k = random.randint(0,4)\n",
    "    #next_word = next_words[k].data[0]\n",
    "    ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "  \n",
    "  return ys\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out, w2 = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1) # change this for top k\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from previous state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = torch.load('../models/epochs_30_LM.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0.,   1.,  81.,  ..., 139.,   8., 139.],\n",
      "         [ 52., 139.,  52.,  ..., 143.,  45., 143.],\n",
      "         [  8., 141.,  71.,  ..., 139.,  88., 142.],\n",
      "         ...,\n",
      "         [ 74., 138.,  54.,  ..., 139.,  85., 140.],\n",
      "         [ 50., 139.,  50.,  ..., 143.,  47., 143.],\n",
      "         [  8., 141.,  81.,  ..., 139.,  54., 139.]]])\n"
     ]
    }
   ],
   "source": [
    "myDs = MidiDataset('../numpy_path', 150, 'N/A', '.npy')\n",
    "dataloader = DataLoader(myDs, 1, shuffle=True)\n",
    "\n",
    "for _, item in enumerate(dataloader):\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = './saved_data/'\n",
    "# data_save_name = 'music_item_data_0-10000.pkl'\n",
    "# numpy_path = '../numpy_path'\n",
    "\n",
    "# numpy_files = get_files(numpy_path, extensions='.npy', recurse=True); len(numpy_files)\n",
    "\n",
    "# def create_databunch(files, path):\n",
    "#     #save_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "#     vocab = MusicVocab.create()\n",
    "#     processors = [OpenNPFileProcessor(), MusicItemProcessor()]\n",
    "\n",
    "#     #data = MusicDataBunch.from_files(midi_files, path, processors=processors, encode_position=True)\n",
    "#     data = MusicDataBunch.from_files(files, path, processors=processors, encode_position=True)\n",
    "#     return data\n",
    "\n",
    "# all_data = create_databunch(numpy_files, data_path); all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.,   1.,   8.,  ..., 141.,  44., 145.],\n",
      "        [  8., 140.,  56.,  ..., 138.,  75., 140.],\n",
      "        [ 51., 141.,  39.,  ..., 157.,  51., 145.],\n",
      "        ...,\n",
      "        [ 70., 138.,   8.,  ..., 140.,  78., 138.],\n",
      "        [ 70., 138.,  66.,  ..., 145.,   8., 141.],\n",
      "        [ 47., 141.,   8.,  ..., 168.,  70., 168.]])\n",
      "torch.Size([7800])\n",
      "tensor([  0.,   1.,   8.,  ..., 168.,  70., 168.])\n"
     ]
    }
   ],
   "source": [
    "print(myDs[0])\n",
    "new_tens = myDs[0].reshape(myDs[0].shape[0] * myDs[0].shape[1])\n",
    "print(new_tens.shape)\n",
    "print(new_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate topk/greedy outputs from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREEDY:  tensor([  0,   1,   8, 145,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "          8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,\n",
      "         38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "          8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,\n",
      "         38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "          8, 139,  38, 139,   8, 139,  38, 139,   8, 139,   8, 139,  38, 139,\n",
      "          8, 139,  81, 153,  78, 153,  74, 153,  69, 153,  66, 153,  62, 153,\n",
      "         38, 139], device='cuda:0')\n",
      "TOPK:  tensor([  0,   1,  38, 139,   8, 139,  38, 140,   8, 139,  50, 140,   8, 139,\n",
      "         38, 139,   8, 138,  50, 138,  38, 138,  38, 139,   8, 139,  50, 139,\n",
      "          8, 138,  50, 140,  38, 140,   8, 139,  38, 140,  38, 140,   8, 140,\n",
      "         38, 138,  38, 138,  38, 139,  38, 139,   8, 139,  38, 140,  38, 140,\n",
      "         38, 140,   8, 139,  38, 139,   8, 139,  38, 140,   8, 140,  50, 139,\n",
      "          8, 138,  38, 138,   8, 138,  38, 140,   8, 140,  38, 139,  50, 140,\n",
      "         38, 140,   8, 140,  38, 138,   8, 139,  38, 140,  38, 139,  38, 140,\n",
      "          8, 140], device='cuda:0')\n",
      "SRC:  tensor([  0,   1,  63, 139,  59, 139,  47, 138,   8, 138,  66, 138,   8, 138,\n",
      "         71, 139,  66, 139,  47, 138,  47, 138,   8, 138,  75, 139,   8, 138,\n",
      "         66, 138,  63, 139,  59, 139,   8, 139,  71, 139,  66, 139,  42, 139,\n",
      "         42, 139,   8, 138,  75, 139,   8, 138,  66, 138,  63, 139,  59, 139,\n",
      "         47, 138,  47, 138,   8, 139,  71, 139,  66, 139,  47, 139,  47, 138,\n",
      "          8, 138,  75, 139,   8, 138,  66, 138,  63, 139,  59, 139,   8, 139,\n",
      "         75, 139,  71, 139,  66, 139,  42, 139,   8, 139,  68, 139,  64, 139,\n",
      "         59, 139], device='cuda:0')\n",
      "TOPK:  0.01\n",
      "GREEDY:  0.01\n"
     ]
    }
   ],
   "source": [
    "myModel.eval()\n",
    "# ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "#src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]))\n",
    "#src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]])).cuda()\n",
    "idx = 1\n",
    "src = myDs[idx].reshape(myDs[idx].shape[0] * myDs[idx].shape[1])[:100].unsqueeze(dim=0).long().cuda() # all_data.valid_ds[1][0].to_tensor()[:100].unsqueeze(dim=0)\n",
    "#print(src.size())\n",
    "src_mask = Variable(torch.ones(1, 1, 100)).unsqueeze(dim=0).cuda() # 26 was 10\n",
    "output = greedy_decode(myModel.cuda(), src, src_mask, max_len=100, start_symbol=0)\n",
    "output2 = topk_decode(myModel.cuda(), src, src_mask, max_len=100, start_symbol=0, k=2)\n",
    "\n",
    "#print(output2[0])\n",
    "#print(output[0])\n",
    "\n",
    "output.cuda()\n",
    "output2.cuda()\n",
    "\n",
    "print(\"GREEDY: \", output[0])\n",
    "print(\"TOPK: \", output2[0])\n",
    "print(\"SRC: \", src[0])\n",
    "\n",
    "ncorrect = 0\n",
    "for i in range(len(src)):\n",
    "  if src[0][i] == output2[0][i]:\n",
    "    ncorrect += 1\n",
    "print(\"TOPK: \", ncorrect / len(src[0]))\n",
    "\n",
    "ncorrect = 0\n",
    "for i in range(len(src)):\n",
    "  if src[0][i] == output[0][i]:\n",
    "    ncorrect += 1\n",
    "print(\"GREEDY: \", ncorrect / len(src[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert outputs to .mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC.SHP:  torch.Size([1, 100])\n",
      "OUTPUT.SHP:  torch.Size([1, 100])\n",
      "OUTPUT2.SHP:  torch.Size([1, 100])\n",
      "tensor([[  0,   1,  63, 139,  59, 139,  47, 138,   8, 138,  66, 138,   8, 138,\n",
      "          71, 139,  66, 139,  47, 138,  47, 138,   8, 138,  75, 139,   8, 138,\n",
      "          66, 138,  63, 139,  59, 139,   8, 139,  71, 139,  66, 139,  42, 139,\n",
      "          42, 139,   8, 138,  75, 139,   8, 138,  66, 138,  63, 139,  59, 139,\n",
      "          47, 138,  47, 138,   8, 139,  71, 139,  66, 139,  47, 139,  47, 138,\n",
      "           8, 138,  75, 139,   8, 138,  66, 138,  63, 139,  59, 139,   8, 139,\n",
      "          75, 139,  71, 139,  66, 139,  42, 139,   8, 139,  68, 139,  64, 139,\n",
      "          59, 139]], device='cuda:0')\n",
      "tensor([[  0,   1,   8, 145,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "           8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,\n",
      "          38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "           8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,\n",
      "          38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "           8, 139,  38, 139,   8, 139,  38, 139,   8, 139,   8, 139,  38, 139,\n",
      "           8, 139,  81, 153,  78, 153,  74, 153,  69, 153,  66, 153,  62, 153,\n",
      "          38, 139]], device='cuda:0')\n",
      "tensor([[  0,   1,  38, 139,   8, 139,  38, 140,   8, 139,  50, 140,   8, 139,\n",
      "          38, 139,   8, 138,  50, 138,  38, 138,  38, 139,   8, 139,  50, 139,\n",
      "           8, 138,  50, 140,  38, 140,   8, 139,  38, 140,  38, 140,   8, 140,\n",
      "          38, 138,  38, 138,  38, 139,  38, 139,   8, 139,  38, 140,  38, 140,\n",
      "          38, 140,   8, 139,  38, 139,   8, 139,  38, 140,   8, 140,  50, 139,\n",
      "           8, 138,  38, 138,   8, 138,  38, 140,   8, 140,  38, 139,  50, 140,\n",
      "          38, 140,   8, 140,  38, 138,   8, 139,  38, 140,  38, 139,  38, 140,\n",
      "           8, 140]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./temp_outputs/topk.mid'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from music21 import *\n",
    "import fluidsynth\n",
    "#environment.set()\n",
    "#print(output)\n",
    "output[0, 1] = 1\n",
    "output2[0, 1] = 1\n",
    "#print(src.cpu().numpy())\n",
    "temp_vocab = MusicVocab.create()\n",
    "#print(temp_vocab.stoi)\n",
    "MI = temp_vocab.to_music_item(src.cpu().numpy()[0])\n",
    "MO = temp_vocab.to_music_item(output.cpu().numpy()[0])\n",
    "MT = temp_vocab.to_music_item(output2.cpu().numpy()[0])\n",
    "print(\"SRC.SHP: \", src.shape)\n",
    "print(\"OUTPUT.SHP: \", output.shape)\n",
    "print(\"OUTPUT2.SHP: \", output2.shape)\n",
    "print(src)\n",
    "print(output)\n",
    "print(output2)\n",
    "#print(MI.to_text())\n",
    "#print(MO.to_text())\n",
    "#print(MT.to_text())\n",
    "\n",
    "#new_tens = myDs[0].reshape(myDs[0].shape[0] * myDs[0].shape[1])\n",
    "\n",
    "MMM = temp_vocab.to_music_item(new_tens.numpy().astype(int))\n",
    "MI.stream.write('midi', fp='./temp_outputs/inp.mid')\n",
    "MO.stream.write('midi', fp='./temp_outputs/pred.mid')\n",
    "MT.stream.write('midi', fp='./temp_outputs/topk.mid')\n",
    "#MMM.stream.write('midi', fp='./temp_outputs/inp_test.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify generated song's musical key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxpad n54 d2 n50 d2 n38 d2 xxsep d1 n57 d1 xxsep d1 n62 d2 n57 d2 n38 d2 xxsep d1 n66 d2 xxsep d1 n57 d2 n54 d2 n50 d2 xxsep d2 n62 d2 n57 d2 n33 d2 xxsep d1 n66 d2 xxsep d1 n57 d2 n54 d2 n50 d2 n38 d2 xxsep d2 n62 d2 n57 d2 n38 d2 xxsep d1 n66 d2 xxsep d1 n57 d2 n54 d2 n50 d2 xxsep d2 n66 d2 n62 d2 n57 d2 n33 d2 xxsep d2 n59 d2 n55 d2 n50 d2\n",
      "A#|Bb\n",
      "('F#_minor', Counter({'D': 13, 'A': 10, 'F#|Gb': 8, 'B': 1, 'G': 1}))\n",
      "('F_major', Counter({'F': 22}))\n",
      "('F_major', Counter({'F': 25, 'C': 4, 'A': 4}))\n"
     ]
    }
   ],
   "source": [
    "src_mitem = MusicItem.from_file('./temp_outputs/inp.mid', MusicVocab.create())\n",
    "m_item = MusicItem.from_file('./temp_outputs/topk.mid', MusicVocab.create())\n",
    "m_item2 = MusicItem.from_file('./temp_outputs/pred.mid', MusicVocab.create())\n",
    "print(src_mitem.to_text())\n",
    "print(int_to_note(34))\n",
    "print(calculate_score(src_mitem))\n",
    "print(calculate_score(m_item))\n",
    "print(calculate_score(m_item2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert .mid to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './temp_outputs/inp.mid'\n",
    "fs = FluidSynth(sound_font='../misc/FluidR3_GM.sf2')\n",
    "fs.midi_to_audio(filepath, '{}.wav'.format(filepath))\n",
    "\n",
    "filepath = './temp_outputs/pred.mid'\n",
    "fs = FluidSynth(sound_font='../misc/FluidR3_GM.sf2')\n",
    "fs.midi_to_audio(filepath, '{}.wav'.format(filepath))\n",
    "\n",
    "filepath = './temp_outputs/topk.mid'\n",
    "fs = FluidSynth(sound_font='../misc/FluidR3_GM.sf2')\n",
    "fs.midi_to_audio(filepath, '{}.wav'.format(filepath))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95fee283cad2380c3bbb086be18af1e1d950b8d84e571fde4cd1d4f314b30685"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
