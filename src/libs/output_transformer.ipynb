{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/libs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our file imports\n",
    "from music_transformer import *\n",
    "from transformer_training_helpers import *\n",
    "from song_classification import *\n",
    "\n",
    "# musicautobot\n",
    "from musicautobot.numpy_encode import *\n",
    "from musicautobot.config import *\n",
    "from musicautobot.music_transformer import *\n",
    "from musicautobot.utils.midifile import *\n",
    "from musicautobot.utils.file_processing import process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_decode(model, src, src_mask, max_len, start_symbol, k):\n",
    "  memory = model.encode(src, src_mask)\n",
    "  ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "  for i in range(max_len-1):\n",
    "    out, w2 = model.decode(memory, src_mask,\n",
    "                       Variable(ys),\n",
    "                       Variable(subsequent_mask(ys.size(1))\n",
    "                                .type_as(src.data)))\n",
    "    prob = model.generator(out[:, -1])\n",
    "    _, next_words = torch.topk(prob, k = k, dim = 1)\n",
    "    # if starting, then create \n",
    "    #print(next_words)\n",
    "    if i == 0:\n",
    "      next_word = next_words[0][0].data.item()\n",
    "    else:\n",
    "      k2 = random.randint(0,k-1)\n",
    "      next_word = next_words[0][k2].data.item()\n",
    "    #print(next_word)\n",
    "    #k = random.randint(0,4)\n",
    "    #next_word = next_words[k].data[0]\n",
    "    ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "  \n",
    "  return ys\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out, w2 = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1) # change this for top k\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from previous state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../models/epochs_30_LM.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trevi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\fastai\\core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(a, dtype=dtype, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MusicDataBunch;\n",
       "\n",
       "Train: LabelList (1060 items)\n",
       "x: MusicItemList\n",
       "\n",
       "MusicItem - (9818,)\n",
       "xxbos xxpad n54 d2 n50 d2 n38 d1 xxsep d1...,\n",
       "MusicItem - (6616,)\n",
       "xxbos xxpad n64 d2 n61 d2 n57 d2 n52 d4...,\n",
       "MusicItem - (9758,)\n",
       "xxbos xxpad xxsep d7 n54 d11 xxsep d1 n64 d11...,\n",
       "MusicItem - (1236,)\n",
       "xxbos xxpad n76 d32 n72 d32 n67 d32 n64 d32...,\n",
       "MusicItem - (7064,)\n",
       "xxbos xxpad n76 d2 n72 d2 n60 d29 n57 d28...\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: saved_data;\n",
       "\n",
       "Valid: LabelList (117 items)\n",
       "x: MusicItemList\n",
       "\n",
       "MusicItem - (11442,)\n",
       "xxbos xxpad xxsep d9 n55 d1 xxsep d1 n57 d1...,\n",
       "MusicItem - (15824,)\n",
       "xxbos xxpad xxsep d11 n89 d1 n88 d1 xxsep d1...,\n",
       "MusicItem - (2552,)\n",
       "xxbos xxpad n70 d10 n67 d10 n62 d10 n58 d10...,\n",
       "MusicItem - (5066,)\n",
       "xxbos xxpad n58 d1 n55 d1 n51 d1 n39 d4...,\n",
       "MusicItem - (5798,)\n",
       "xxbos xxpad n60 d128 n55 d32 n51 d32 n48 d12...\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: saved_data;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './saved_data/'\n",
    "data_save_name = 'music_item_data_0-10000.pkl'\n",
    "numpy_path = '../numpy_path'\n",
    "\n",
    "numpy_files = get_files(numpy_path, extensions='.npy', recurse=True); len(numpy_files)\n",
    "\n",
    "def create_databunch(files, path):\n",
    "    #save_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "    vocab = MusicVocab.create()\n",
    "    processors = [OpenNPFileProcessor(), MusicItemProcessor()]\n",
    "\n",
    "    #data = MusicDataBunch.from_files(midi_files, path, processors=processors, encode_position=True)\n",
    "    data = MusicDataBunch.from_files(files, path, processors=processors, encode_position=True)\n",
    "    return data\n",
    "\n",
    "all_data = create_databunch(numpy_files, data_path); all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate topk/greedy outputs from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREEDY:  tensor([  0,   1,   8, 145,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "          8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,\n",
      "         38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "          8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,\n",
      "         38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "          8, 139,  38, 139,   8, 139,  38, 139,   8, 139,   8, 139,  38, 139,\n",
      "          8, 139,  81, 153,  78, 153,  74, 153,  69, 153,  66, 153,  62, 153,\n",
      "         38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "          8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,\n",
      "         38, 139,   8, 139,  38, 139,   8, 139,  38, 139,   8, 139,  38, 139,\n",
      "          8, 139,  38, 139,   8, 139,  38, 139,   8, 139], device='cuda:0')\n",
      "TOPK:  tensor([  0,   1,  38, 138,   8, 138,  38, 139,   8, 139,  50, 138,  38, 139,\n",
      "          8, 139,  50, 138,  38, 138,  38, 139,  38, 139,  38, 138,  38, 138,\n",
      "          8, 138,  50, 138,   8, 139,  50, 138,  38, 138,   8, 139,  50, 138,\n",
      "          8, 139,  38, 138,   8, 139,  38, 139,  38, 138,  38, 138,   8, 139,\n",
      "         50, 138,   8, 139,  38, 138,  38, 139,   8, 139,  50, 138,   8, 138,\n",
      "         50, 138,  38, 138,  38, 139,  38, 138,  38, 138,  38, 140,   8, 140,\n",
      "         50, 140,   8, 140,  50, 138,  38, 140,   8, 138,  50, 139,  38, 139,\n",
      "         38, 138,   8, 139,  50, 138,  38, 139,  38, 139,   8, 138,  81, 153,\n",
      "          8, 140,  50, 139,   8, 140,  38, 139,   8, 139,  38, 139,   8, 140,\n",
      "         38, 138,  38, 139,  38, 139,   8, 140,  38, 138,  38, 139,  38, 138,\n",
      "         38, 138,   8, 139,  50, 138,   8, 138,  38, 139], device='cuda:0')\n",
      "SRC:  tensor([  0,   1,   8, 148,  98, 138,  97, 138,   8, 138,  95, 138,  93, 138,\n",
      "         92, 138,   8, 138,  90, 138,  88, 138,  86, 138,   8, 138,  85, 138,\n",
      "         83, 138,  81, 138,   8, 138,  80, 138,  78, 138,  76, 138,   8, 138,\n",
      "         86, 139,  78, 167,  78, 138,  78, 143,  74, 167,  74, 138,  71, 167,\n",
      "         71, 138,  67, 167,  67, 138,  55, 167,  55, 167,  43, 167,   8, 138,\n",
      "         78, 138,  74, 138,  71, 138,  67, 138,   8, 138,  78, 138,  74, 138,\n",
      "         71, 138,  67, 138,   8, 138,  86, 139,  78, 138,  74, 138,  71, 138,\n",
      "         67, 138], device='cuda:0')\n",
      "TOPK:  0.01\n",
      "GREEDY:  0.01\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "#src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]))\n",
    "#src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]])).cuda()\n",
    "src = all_data.valid_ds[1][0].to_tensor()[:100].unsqueeze(dim=0)\n",
    "#print(src.size())\n",
    "src_mask = Variable(torch.ones(1, 1, 100)).unsqueeze(dim=0).cuda() # 26 was 10\n",
    "output = greedy_decode(model.cuda(), src, src_mask, max_len=150, start_symbol=0)\n",
    "output2 = topk_decode(model.cuda(), src, src_mask, max_len=150, start_symbol=0, k=2)\n",
    "\n",
    "#print(output2[0])\n",
    "#print(output[0])\n",
    "\n",
    "output.cuda()\n",
    "output2.cuda()\n",
    "\n",
    "print(\"GREEDY: \", output[0])\n",
    "print(\"TOPK: \", output2[0])\n",
    "print(\"SRC: \", src[0])\n",
    "\n",
    "ncorrect = 0\n",
    "for i in range(len(src)):\n",
    "  if src[0][i] == output2[0][i]:\n",
    "    ncorrect += 1\n",
    "print(\"TOPK: \", ncorrect / len(src[0]))\n",
    "\n",
    "ncorrect = 0\n",
    "for i in range(len(src)):\n",
    "  if src[0][i] == output[0][i]:\n",
    "    ncorrect += 1\n",
    "print(\"GREEDY: \", ncorrect / len(src[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert outputs to .mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC.SHP:  torch.Size([1, 100])\n",
      "OUTPUT.SHP:  torch.Size([1, 150])\n",
      "OUTPUT2.SHP:  torch.Size([1, 150])\n",
      "tensor([[  0,   1,  38, 138,   8, 138,  38, 139,   8, 139,  50, 138,  38, 139,\n",
      "           8, 139,  50, 138,  38, 138,  38, 139,  38, 139,  38, 138,  38, 138,\n",
      "           8, 138,  50, 138,   8, 139,  50, 138,  38, 138,   8, 139,  50, 138,\n",
      "           8, 139,  38, 138,   8, 139,  38, 139,  38, 138,  38, 138,   8, 139,\n",
      "          50, 138,   8, 139,  38, 138,  38, 139,   8, 139,  50, 138,   8, 138,\n",
      "          50, 138,  38, 138,  38, 139,  38, 138,  38, 138,  38, 140,   8, 140,\n",
      "          50, 140,   8, 140,  50, 138,  38, 140,   8, 138,  50, 139,  38, 139,\n",
      "          38, 138,   8, 139,  50, 138,  38, 139,  38, 139,   8, 138,  81, 153,\n",
      "           8, 140,  50, 139,   8, 140,  38, 139,   8, 139,  38, 139,   8, 140,\n",
      "          38, 138,  38, 139,  38, 139,   8, 140,  38, 138,  38, 139,  38, 138,\n",
      "          38, 138,   8, 139,  50, 138,   8, 138,  38, 139]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./temp_outputs/topk.mid'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from music21 import *\n",
    "import fluidsynth\n",
    "#environment.set()\n",
    "#print(output)\n",
    "\n",
    "#print(src.cpu().numpy())\n",
    "MI = all_data.vocab.to_music_item(src.cpu().numpy()[0])\n",
    "MO = all_data.vocab.to_music_item(output.cpu().numpy()[0])\n",
    "MT = all_data.vocab.to_music_item(output2.cpu().numpy()[0])\n",
    "print(\"SRC.SHP: \", src.shape)\n",
    "print(\"OUTPUT.SHP: \", output.shape)\n",
    "print(\"OUTPUT2.SHP: \", output2.shape)\n",
    "print(output2)\n",
    "#print(MI.to_text())\n",
    "#print(MO.to_text())\n",
    "MI.stream.write('midi', fp='./temp_outputs/inp.mid')\n",
    "MO.stream.write('midi', fp='./temp_outputs/pred.mid')\n",
    "MT.stream.write('midi', fp='./temp_outputs/topk.mid')\n",
    "#path = os.path.join('./','inp.mid')\n",
    "#print_play_mid('./inp.mid')\n",
    "#print_mid('./inp.mid')\n",
    "#print_mid('./pred.mid')\n",
    "#print_mid('./topk.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify generated song's musical key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxpad xxsep d11 n89 d1 n88 d1 xxsep d1 n86 d1 n84 d1 n83 d1 xxsep d1 n81 d1 n79 d1 n77 d1 xxsep d1 n76 d1 n74 d1 n72 d1 xxsep d1 n71 d1 n69 d1 n67 d1 xxsep d1 n77 d2 n69 d2 n65 d2 n62 d2 n58 d2 n46 d16 n34 d16 xxsep d1 n69 d2 n65 d2 n62 d2 n58 d2 xxsep d1 n69 d2 n65 d2 n62 d2 n58 d2 xxsep d1 n77 d2 n69 d2 n65 d2 n62 d2 n58 d2 xxsep d27 n46 d14 n34 d14\n",
      "A#|Bb\n",
      "('F_major', Counter({'F': 8, 'A#|Bb': 8, 'D': 6, 'A': 6, 'E': 2, 'C': 2, 'B': 2, 'G': 2}))\n",
      "('F_major', Counter({'F': 31, 'C': 2}))\n",
      "('F_major', Counter({'F': 37, 'C': 4, 'A': 4}))\n"
     ]
    }
   ],
   "source": [
    "src_mitem = MusicItem.from_file('./temp_outputs/inp.mid', MusicVocab.create())\n",
    "m_item = MusicItem.from_file('./temp_outputs/topk.mid', MusicVocab.create())\n",
    "m_item2 = MusicItem.from_file('./temp_outputs/pred.mid', MusicVocab.create())\n",
    "print(src_mitem.to_text())\n",
    "print(int_to_note(34))\n",
    "print(calculate_score(src_mitem))\n",
    "print(calculate_score(m_item))\n",
    "print(calculate_score(m_item2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
