{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "# Whether to run my code, or the original (working) tutorial's\n",
    "TUTORIAL = False\n",
    "COLAB = False\n",
    "\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random, time\n",
    "import torch\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torchaudio import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, SubsetRandomSampler\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    COLAB = True\n",
    "    print('Running on CoLab')\n",
    "else:\n",
    "    COLAB = False\n",
    "    print('Not running on CoLab')\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    base = Path(\"/content/drive/MyDrive/Colab Notebooks/scratch\")\n",
    "elif TUTORIAL:\n",
    "    base = Path(\"C:\\\\Users\\\\bkweb\\\\Documents\\\\dragn\\\\ml_from_scratch\")\n",
    "else:\n",
    "    base = Path(\"C:/Users/bkweb/Documents/dragn/MusGen/src\")\n",
    "sys.path.append(str(base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Prepare training data\n",
    "# ----------------------------\n",
    "\n",
    "if TUTORIAL:\n",
    "    # ----------------------------\n",
    "    # use UrbanSound8k metadata file from tutorial\n",
    "    # ----------------------------\n",
    "\n",
    "    download_path = base/'UrbanSound8K'\n",
    "\n",
    "    # Read metadata file\n",
    "    metadata_file = download_path/'metadata'/'UrbanSound8K.csv'\n",
    "    df = pd.read_csv(metadata_file)\n",
    "    df.head()\n",
    "\n",
    "    # Construct file path by concatenating fold and file name\n",
    "    df['relative_path'] = '/fold' + df['fold'].astype(str) + '/' + df['slice_file_name'].astype(str)\n",
    "\n",
    "    # Take relevant columns\n",
    "    df = df[['relative_path', 'classID']]\n",
    "    data_path = download_path/'audio'\n",
    "else:\n",
    "    # # ----------------------------\n",
    "    # # use classified_songs to collect key labels\n",
    "    # # ----------------------------\n",
    "\n",
    "    # Read in the file with song filenames and corresponding labels, and drop duplicates\n",
    "    file = Path(base, 'song_data/classified_songs_V2.csv')\n",
    "    df = pd.read_csv(file, sep='\\t')[['Id', 'Key']]\n",
    "    df = df.drop_duplicates(subset=['Id'])\n",
    "\n",
    "    # Create a dictionary mapping filenames to their relative paths\n",
    "    f_to_rp = dict()\n",
    "    data_path = base.joinpath('wav_data_collections')\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for f in files:\n",
    "            f_to_rp[Path(f).stem] = Path((root + '\\\\' + f)[63:])\n",
    "\n",
    "    # Since this is binary classification, replace mode labels with either 1 or 0\n",
    "    mask = df['Key'].str.contains('minor')\n",
    "    df['Key'] = df['Key'].where(mask, other = 1)\n",
    "    df['Key'] = df['Key'].where(~mask, other = 0)\n",
    "\n",
    "    # Re-label columns to match SoundDS expectations\n",
    "    df.rename(columns={'Id': 'relative_path', 'Key': 'classID'}, inplace=True)\n",
    "\n",
    "    # Filter out entries we don't have in .wav format, and add relevant relative_path s to df\n",
    "    mask = df['relative_path'].apply(lambda x: x in f_to_rp.keys())\n",
    "    df = df[mask]\n",
    "    df = df.replace({'relative_path': f_to_rp})\n",
    "    df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioUtil Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioUtil():\n",
    "    # ----------------------------\n",
    "    # Load an audio file. Return the signal as a tensor and the sample rate\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def open(audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        return (sig, sr)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Convert the given audio to the desired number of channels\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def rechannel(aud, new_channel):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sig.shape[0] == new_channel):\n",
    "            # Nothing to do\n",
    "            return aud\n",
    "\n",
    "        if (new_channel == 1):\n",
    "            # Convert from stereo to mono by selecting only the first channel\n",
    "            resig = sig[:1, :]\n",
    "        else:\n",
    "            # Convert from mono to stereo by duplicating the first channel\n",
    "            resig = torch.cat([sig, sig])\n",
    "\n",
    "        return ((resig, sr))\n",
    "\n",
    "    # ----------------------------\n",
    "    # Since Resample applies to a single channel, we resample one channel at a time\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def resample(aud, newsr):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sr == newsr):\n",
    "            # Nothing to do\n",
    "            return aud\n",
    "\n",
    "        num_channels = sig.shape[0]\n",
    "        # Resample first channel\n",
    "        resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "        if (num_channels > 1):\n",
    "            # Resample the second channel and merge both channels\n",
    "            retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "\n",
    "        return ((resig, newsr))\n",
    "    # ----------------------------\n",
    "    # Pad (or truncate) the audio to the desired length 'max_ms' in milliseconds\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def pad_trunc(aud, max_ms):\n",
    "        sig, sr = aud\n",
    "        num_rows, sig_len = sig.shape\n",
    "        max_len = sr//1000 * max_ms\n",
    "\n",
    "        if (sig_len >= max_len):\n",
    "            # Extract random sample of length max_len from audio\n",
    "            rand_indx = random.randint(0, round(sig_len) - round(max_len))\n",
    "\n",
    "            sig = sig[:, rand_indx: rand_indx + max_len]\n",
    "        \n",
    "        elif (sig_len < max_len):\n",
    "            # Length of padding to add at the beginning and end of the signal\n",
    "            pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "            pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "            # Pad with 0s\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "            sig = torch.cat([pad_begin, sig, pad_end], 1)\n",
    "\n",
    "        return (sig, sr)\n",
    "    # ----------------------------\n",
    "    # Shifts the signal to the left or right by some percent. Values at the end\n",
    "    #   are wrapped around to the start of the transformed signal.\n",
    "    # ---------------------------- \n",
    "    @staticmethod\n",
    "    def time_shift(aud, shift_limit):\n",
    "        sig, sr = aud\n",
    "        _, sig_len = sig.shape\n",
    "        shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "        return (sig.roll(shift_amt), sr)\n",
    "    # ----------------------------\n",
    "    # Generate a Spectrogram\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def spectrogram(aud, n_mels = 64, n_fft=1024, hop_len=None):\n",
    "        sig, sr = aud\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo, etc\n",
    "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "        # Convert to dB\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        return (spec)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
    "    # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
    "    # overfitting and to help the model generalise better. The masked sections are\n",
    "    # replaced with the mean value.\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def spectro_augment(spec, max_mask_pct = 0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "        \n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "        \n",
    "        return (aug_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sound Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "\n",
    "class SoundDS(Dataset):\n",
    "    def __init__(self, df, data_path):\n",
    "        self.df = df\n",
    "        self.data_path = str(data_path)\n",
    "        self.duration = 12000    # The length, in milliseconds, of each sample\n",
    "        self.sr = 44100 # The rate, in kHz\n",
    "        self.channel = 2\n",
    "        self.shift_pct = 0.4\n",
    "\n",
    "    # ----------------------------\n",
    "    # Number of items in dataset\n",
    "    # ----------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Get i'th item in dataset\n",
    "    # ----------------------------\n",
    "    def __getitem__(self, idx):\n",
    "        # Absolute file path of the audio file - concatenat the audio directory with\n",
    "        # the relative path\n",
    "        if TUTORIAL:\n",
    "            audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
    "        else:\n",
    "            audio_file = data_path.joinpath(self.df.loc[idx, 'relative_path'])\n",
    "\n",
    "        # Get the Class ID\n",
    "        class_id = self.df.loc[idx, 'classID']\n",
    "    \n",
    "        aud = AudioUtil.open(audio_file)\n",
    "        # Some sounds have a higher sample rate, or fewer channels compared to the\n",
    "        #   majority. So make all sounds have the same number of channels and same \n",
    "        #   sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
    "        #   result in arrays of different lengths, even though the sound duration is\n",
    "        #   the same.\n",
    "\n",
    "        reaud = AudioUtil.resample(aud, self.sr)\n",
    "        rechan = AudioUtil.rechannel(reaud, self.channel)\n",
    "\n",
    "        dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "        shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
    "        sgram = AudioUtil.spectrogram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "        aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "        return aug_sgram, class_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train-val-test and instantiate DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 1946\n",
      "Size of validation set: 243\n",
      "Size of test set: 243\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Split by train-val-test and instantiate DataLoaders\n",
    "# ----------------------------\n",
    "\n",
    "# I use the validation set for evaluation during training, and reserve the test set for inference only\n",
    "TEST_PERCENT = .1   # Proportion of original data to use as test data\n",
    "VAL_PERCENT = .1    # Proportion of original data to use as validation data\n",
    "CROSS_VAL = False   # Whether to perform k-fold cross-validation\n",
    "\n",
    "if TEST_PERCENT == 1:\n",
    "    raise ValueError(\"All of the data is declared to be test data\")\n",
    "\n",
    "myds = SoundDS(df, data_path)\n",
    "\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * (1 - TEST_PERCENT))\n",
    "num_test = num_items - num_train\n",
    "\n",
    "if CROSS_VAL:\n",
    "    # Create a cross-validator object\n",
    "    kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "    # When using cross-validation, we here split the data in to initial training and test data. Our\n",
    "    #   folds will be drawn SOLELY from the train_ds, and the test_ds will only be used later.\n",
    "    train_ds, test_ds = random_split(myds, [num_train, num_test])\n",
    "    print(kfold)\n",
    "    print(len(train_ds), len(test_ds))\n",
    "else:\n",
    "    # Random split between training and validation\n",
    "    num_val = round(num_items * (VAL_PERCENT))\n",
    "    num_train = num_items - num_val - num_test\n",
    "\n",
    "    train_ds, val_ds, test_ds = random_split(myds, [num_train, num_val, num_test])\n",
    "\n",
    "    # Create training and validation data loaders\n",
    "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "    val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=True)\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=True)\n",
    "    print(f\"Size of training set: {len(train_ds)}\")\n",
    "    print(f\"Size of validation set: {len(val_ds)}\") # Not currently using this at all in the code that's not cross-validation\n",
    "    print(f\"Size of test set: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Audio Classification Model\n",
    "# ----------------------------\n",
    "class AudioClassifier (nn.Module):\n",
    "    # ----------------------------\n",
    "    # Build the model architecture\n",
    "    # ----------------------------\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Third Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Fourth Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=64, out_features=self.num_classes)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "    # ----------------------------\n",
    "    # Forward pass computations\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Final output\n",
    "        return x\n",
    "\n",
    "# Create the model and put it on the GPU if available\n",
    "myModel = AudioClassifier(num_classes=np.unique(df['classID']).shape[0])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(device)\n",
    "# Check that it is on Cuda\n",
    "next(myModel.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional) k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My addition, to enable k-fold cross-validation\n",
    "if CROSS_VAL:\n",
    "    def train_epoch(model, data_loader, optimizer, loss_fn, scheduler, device):\n",
    "        running_loss = 0.0\n",
    "        correct_pred = 0\n",
    "        total_pred = 0\n",
    "        model.train()\n",
    "        # Loop through the data loader by batch\n",
    "        for i, data in enumerate(data_loader):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            correct_pred += torch.sum(prediction == labels).sum().item()\n",
    "            total_pred += prediction.shape[0]\n",
    "        \n",
    "        num_batches = len(data_loader)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        accuracy = correct_pred/total_pred\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "\n",
    "    def val_epoch(model, data_loader, loss_fn, device):\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_pred = 0\n",
    "        total_pred = 0\n",
    "        for i, data in enumerate(data_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_pred += (prediction == labels).sum().item()\n",
    "            total_pred += prediction.shape[0]\n",
    "            \n",
    "        num_batches = len(data_loader)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        accuracy = correct_pred/total_pred\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "        \n",
    "    # ----------------------------\n",
    "    # Training Loop\n",
    "    # ----------------------------\n",
    "    def training(model, num_epochs, train_dl, val_dl, device, history):\n",
    "        # Loss Function, Optimizer and Scheduler\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                    steps_per_epoch=int(len(train_dl)),\n",
    "                                                    epochs=num_epochs,\n",
    "                                                    anneal_strategy='linear')\n",
    "        \n",
    "        # Repeat for each epoch\n",
    "        for epoch in range(num_epochs):\n",
    "            # Train the model for one epoch, updating the weights\n",
    "            train_loss, train_acc = train_epoch(model, train_dl, optimizer, criterion, scheduler, device)\n",
    "            # Evaluate the model on the validation set for the epoch\n",
    "            val_loss, val_acc = val_epoch(model, val_dl, criterion, device)\n",
    "\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_acc'].append(val_acc)\n",
    "\n",
    "            print(f'Epoch: {epoch + 1}/{num_epochs}, avg_train_loss: {train_loss:.2f}, avg_val_loss: {val_loss:.2f}, avg_train_acc: {train_acc * 100:.2f}%, avg_val_acc: {val_acc * 100:.2f}%')\n",
    "            print(f'Epoch: {epoch + 1}/{num_epochs}, avg_train_loss: {train_loss:.2f}, avg_val_loss: {val_loss:.2f}, avg_train_acc: {train_acc * 100:.2f}%, avg_val_acc: {val_acc * 100:.2f}%')\n",
    "\n",
    "\n",
    "    if CROSS_VAL:\n",
    "        foldperf = dict()\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(train_ds)):\n",
    "            # foldperf[f\"fold{fold + 1}\"] = history # Delete this once I know it's working\n",
    "            history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[]}\n",
    "            print(f\"Fold {fold + 1}\")\n",
    "\n",
    "            train_sampler = SubsetRandomSampler(train_idx)\n",
    "            val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "            # Create training and validation data loaders\n",
    "            train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, sampler=train_sampler)\n",
    "            val_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, sampler=val_sampler)\n",
    "\n",
    "            num_epochs=5\n",
    "            training(myModel, num_epochs, train_dl=train_dl, val_dl=val_dl, device=device, history=history)\n",
    "            foldperf[f\"fold{fold + 1}\"] = history\n",
    "        torch.save(myModel, f\"dev_CNN_{num_epochs}_epochs_{kfold.get_n_splits()}_folds.pt\")\n",
    "    \n",
    "    f_train_loss, f_test_loss, f_train_acc, f_test_acc = [], [], [], []\n",
    "\n",
    "    k = kfold.get_n_splits()\n",
    "    for f in range(1, k + 1):\n",
    "        f_train_loss += (foldperf[f\"fold{f}\"]['train_loss'])\n",
    "        f_test_loss += (foldperf[f\"fold{f}\"]['val_loss'])\n",
    "        f_train_acc += (foldperf[f\"fold{f}\"]['train_acc'])\n",
    "        f_test_acc += (foldperf[f\"fold{f}\"]['val_acc'])\n",
    "    print(f\"Performance of {k}-fold cross validation\")\n",
    "    print(f\"\\tAverage train loss: {np.mean(f_train_loss):.2f}\")\n",
    "    print(f\"\\tAverage validation loss: {np.mean(f_test_loss):.2f}\")\n",
    "    print(f\"\\tAverage train accuracy: {np.mean(f_train_acc)*100:.2f}%\")\n",
    "    print(f\"\\tAverage validation accuracy: {np.mean(f_test_acc)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, data_loader, optimizer, loss_fn, scheduler, device):\n",
    "    \"\"\"Train the model for one epoch.\n",
    "\n",
    "    This function makes one pass through the entire training set and backpropagates the loss to update model weights.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn): the pytorch model to train\n",
    "        data_loader (torch.DataLoader()): an iterable wrapper for the training dataset\n",
    "        optimizer (_type_): an optimizer to update model parameters\n",
    "        loss_fn (_type_): the desired loss function to use\n",
    "        scheduler (_type_): _description_\n",
    "        device (_type_): either 'cpu' or a variation of 'cuda'\n",
    "\n",
    "    Returns:\n",
    "        float: the average loss over the epoch\n",
    "        float: the average accuracy over the epoch\n",
    "    \"\"\"\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct_pred = 0\n",
    "    total_pred = 0\n",
    "    model.train()\n",
    "    # Loop through the data loader by batch\n",
    "    for i, data in enumerate(data_loader):\n",
    "        # Get the input features and target labels, and put them on the GPU\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # Normalize the inputs\n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Keep stats for Loss and Accuracy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, prediction = torch.max(outputs,1)\n",
    "        correct_pred += torch.sum(prediction == labels).sum().item()\n",
    "        total_pred += prediction.shape[0]\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    accuracy = correct_pred/total_pred\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def val_epoch(model, data_loader, loss_fn, device):\n",
    "    \"\"\"Evaluate the model at the end of an epoch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn): the pytorch model to train\n",
    "        data_loader (torch.DataLoader()): an iterable wrapper for the validation dataset\n",
    "        loss_fn (_type_): the desired loss function to use\n",
    "        device (_type_): either 'cpu' or a variation of 'cuda'\n",
    "\n",
    "    Returns:        \n",
    "        float: the average loss over the data\n",
    "        float: the average accuracy over the data\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_pred = 0\n",
    "    total_pred = 0\n",
    "    for i, data in enumerate(data_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Normalize the inputs\n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Keep stats for Loss and Accuracy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, prediction = torch.max(outputs,1)\n",
    "        # Count of predictions that matched the target label\n",
    "        correct_pred += (prediction == labels).sum().item()\n",
    "        total_pred += prediction.shape[0]\n",
    "        \n",
    "    num_batches = len(data_loader)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    accuracy = correct_pred/total_pred\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, num_epochs, train_dl, val_dl, device, state=None, filepath = f'classifier/{time.strftime(\"%m%d-%H%M\")}'):\n",
    "    \"\"\"\n",
    "    TODO: Fill out this docstring\n",
    "    \"\"\"\n",
    "    SAVE_EVERY = 1\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Optimizer and Scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "    if state is None:\n",
    "        orig_n_epoch = 0\n",
    "        # History\n",
    "        history = {'train_loss': [], 'val_loss' : [], 'train_acc' : [], 'val_acc' : []}\n",
    "        state = {\n",
    "        'epoch': 0,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'history': history\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        orig_n_epoch = state['epoch']\n",
    "\n",
    "        # I just added this for loop, so it may not work! CHECK THIS TODO\n",
    "        for epoch in range(orig_n_epoch):\n",
    "            train_loss = state['history']['train_loss'][epoch]\n",
    "            val_loss = state['history']['val_loss'][epoch]\n",
    "            train_acc = state['history']['train_acc'][epoch]\n",
    "            val_acc = state['history']['val_acc'][epoch]\n",
    "            print(f'Epoch: {epoch + 1}/{num_epochs} avg_train_loss: {train_loss:.2f} avg_val_loss: {val_loss:.2f} avg_train_acc: {train_acc * 100:.2f}% avg_val_acc: {val_acc * 100:.2f}%')\n",
    "        model.load_state_dict(state['model'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        history = state['history']\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                    steps_per_epoch=int(len(train_dl)),\n",
    "                                                    epochs=num_epochs,\n",
    "                                                    anneal_strategy='linear')\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(orig_n_epoch, num_epochs):\n",
    "        # Train the model for one epoch, updating the weights\n",
    "        train_loss, train_acc = train_epoch(model, train_dl, optimizer, criterion, scheduler, device)\n",
    "        # Evaluate the model on the validation set for the epoch\n",
    "        val_loss, val_acc = val_epoch(model, val_dl, criterion, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if epoch % SAVE_EVERY == 0:\n",
    "            state['epoch'] = epoch\n",
    "            state['model'] = model.state_dict()\n",
    "            state['optimizer'] = optimizer.state_dict()\n",
    "            state['history'] = history\n",
    "            torch.save(state, filepath)\n",
    "\n",
    "        print(f'Epoch: {epoch + 1}/{num_epochs} avg_train_loss: {train_loss:.2f} avg_val_loss: {val_loss:.2f} avg_train_acc: {train_acc * 100:.2f}% avg_val_acc: {val_acc * 100:.2f}%')\n",
    "\n",
    "    # Visualize the loss curve\n",
    "    plt.plot(history['train_loss'], label='train')\n",
    "    plt.plot(history['val_loss'], label='val')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    state['epoch'] = num_epochs\n",
    "    state['model'] = model.state_dict()\n",
    "    state['optimizer'] = optimizer.state_dict()\n",
    "    state['history'] = history\n",
    "    torch.save(state, filepath)\n",
    "    return model, history, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 avg_train_loss: 0.69 avg_val_loss: 0.72 avg_train_acc: 53.19% avg_val_acc: 51.03%\n",
      "Epoch: 2/30 avg_train_loss: 0.69 avg_val_loss: 0.70 avg_train_acc: 54.93% avg_val_acc: 51.85%\n",
      "Epoch: 3/30 avg_train_loss: 0.70 avg_val_loss: 0.68 avg_train_acc: 48.82% avg_val_acc: 56.38%\n",
      "Epoch: 4/30 avg_train_loss: 0.69 avg_val_loss: 0.68 avg_train_acc: 54.98% avg_val_acc: 55.97%\n",
      "Epoch: 5/30 avg_train_loss: 0.69 avg_val_loss: 0.70 avg_train_acc: 54.32% avg_val_acc: 52.67%\n",
      "Epoch: 6/30 avg_train_loss: 0.68 avg_val_loss: 0.68 avg_train_acc: 58.12% avg_val_acc: 54.32%\n",
      "Epoch: 7/30 avg_train_loss: 0.68 avg_val_loss: 0.70 avg_train_acc: 56.63% avg_val_acc: 52.67%\n",
      "Epoch: 8/30 avg_train_loss: 0.68 avg_val_loss: 0.68 avg_train_acc: 55.86% avg_val_acc: 54.73%\n",
      "Epoch: 9/30 avg_train_loss: 0.68 avg_val_loss: 0.70 avg_train_acc: 55.45% avg_val_acc: 54.32%\n",
      "Epoch: 10/30 avg_train_loss: 0.68 avg_val_loss: 0.70 avg_train_acc: 55.50% avg_val_acc: 56.38%\n"
     ]
    }
   ],
   "source": [
    "num_epochs=30\n",
    "# f_path = f'models/{num_epochs}_epochs_{time.strftime(\"%m%d-%H%M\")}'\n",
    "# f_path = 'models/30_epochs_0622-1647'\n",
    "state = torch.load('models/30_epochs_0622-1647')\n",
    "train(myModel, num_epochs, train_dl=train_dl, val_dl=val_dl, device=device, state=state, filepath=f_path)\n",
    "print(f\"{state['epoch']} epochs completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.70, Accuracy: 0.49\n",
      "Epoch: 1, Loss: 0.69, Accuracy: 0.52\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "def training(model, train_dl, num_epochs, device):\n",
    "    # Loss Function, Optimizer and Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                  steps_per_epoch=int(len(train_dl)),\n",
    "                                                  epochs=num_epochs,\n",
    "                                                  anneal_strategy='linear')\n",
    "\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "            # if i % 10 == 0:    # print every 10 mini-batches\n",
    "            #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "    \n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/total_prediction\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=True)\n",
    "\n",
    "num_epochs=2   # Just for demo, adjust this higher.\n",
    "training(myModel, train_dl, num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on final test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Inference\n",
    "# ----------------------------\n",
    "def inference (model, test_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in test_dl:\n",
    "          # Get the input features and target labels, and put them on the GPU\n",
    "          inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "          # Normalize the inputs\n",
    "          inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "          inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "          # Get predictions\n",
    "          outputs = model(inputs)\n",
    "\n",
    "          # Get the predicted class with the highest score\n",
    "          _, prediction = torch.max(outputs,1)\n",
    "          # Count of predictions that matched the target label\n",
    "          correct_prediction += (prediction == labels).sum().item()\n",
    "          total_prediction += prediction.shape[0]\n",
    "      \n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "\n",
    "# Run inference on trained model with the validation set\n",
    "inference(myModel, test_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1682fff58e0941dfe2be419cba7588859791813d0fc092b99fb5d97aa2e04bce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
